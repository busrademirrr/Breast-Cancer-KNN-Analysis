# ğŸ§¬ Breast Cancer Detection with KNN (PCA vs NCA Analysis)

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![Scikit-Learn](https://img.shields.io/badge/Library-Scikit--Learn-orange)
![License](https://img.shields.io/badge/License-MIT-green)

**[ğŸ‡¹ğŸ‡· TÃ¼rkÃ§e Versiyonu Ä°Ã§in TÄ±klayÄ±nÄ±z / Click here for Turkish Version](#-proje-genel-bakÄ±ÅŸ)**

---

<a name="english"></a>
## ğŸ‡¬ğŸ‡§ Project Overview

This project focuses on the classification of breast cancer tumors as **Malignant (M)** or **Benign (B)** using the **Wisconsin Breast Cancer Dataset**. The core machine learning algorithm employed is **K-Nearest Neighbors (KNN)**.

However, the primary objective of this study is not just classification, but a comparative analysis of **Dimensionality Reduction** techniques. We investigate how reducing the feature space affects the decision boundaries of the KNN classifier.

### ğŸ” Key Techniques & Algorithms
1.  **K-Nearest Neighbors (KNN):** A distance-based classifier optimized using `GridSearchCV` to find the best hyperparameter ($k$).
2.  **Local Outlier Factor (LOF):** An unsupervised anomaly detection method used to identify and remove density-based outliers from the dataset.
3.  **PCA (Principal Component Analysis):** An *unsupervised* linear dimensionality reduction technique that projects data in the direction of maximum variance.
4.  **NCA (Neighborhood Components Analysis):** A *supervised* learning algorithm that learns a linear transformation to maximize the stochastic nearest neighbor classification accuracy.

---

### âš™ï¸ Workflow

1.  **Exploratory Data Analysis (EDA):** Analyzed feature distributions and correlations to understand data structure.
2.  **Data Cleaning:** Applied **LOF** to detect outliers and removed them to improve model generalization.
3.  **Preprocessing:**
    * Encoded target labels (M=1, B=0).
    * Applied **StandardScaler** (Crucial for KNN as it relies on Euclidean distance).
4.  **Model Tuning:** Used `GridSearchCV` to determine the optimal number of neighbors ($k$).
5.  **Dimensionality Reduction & Visualization:**
    * Reduced the 30-feature dataset to 2 dimensions using **PCA** and **NCA**.
    * Visualized and compared the decision boundaries.

---

### ğŸ“Š Visualizations & Results

#### 1. Correlation Analysis
Before selecting features, we examined the correlation matrix to see relationships between features and the diagnosis.
![Correlation Heatmap](images/correlation_heatmap.png)

#### 2. Outlier Detection (LOF)
Using Local Outlier Factor, we identified samples that deviated significantly from the local density of their neighbors.
![Outlier Detection](images/outlier_detection.png)

#### 3. The Showdown: PCA vs. NCA
This comparison highlights the effectiveness of supervised dimensionality reduction.

* **PCA Result:** PCA separates the data based on variance. While useful, the decision boundary is complex and classes overlap slightly.
    ![PCA Boundary](images/pca_boundary.png)

* **NCA Result (Superior):** Since NCA uses the target labels during training, it learns a transformation that explicitly separates the classes. As seen below, the separation is distinct and the decision boundary is cleaner.
    ![NCA Boundary](images/nca_boundary.png)

#### 4. Error Analysis
The final NCA-based KNN model achieved **~99% accuracy**. The plot below highlights the test set predictions, marking the **single misclassified point** in red.
![Wrong Classified](images/wrong_classified.png)

---
---

<a name="turkish"></a>
## ğŸ‡¹ğŸ‡· Proje Genel BakÄ±ÅŸ

Bu proje, **Wisconsin Meme Kanseri Veri Seti** kullanÄ±larak tÃ¼mÃ¶rlerin **KÃ¶tÃ¼ Huylu (M)** veya **Ä°yi Huylu (B)** olarak sÄ±nÄ±flandÄ±rÄ±lmasÄ±nÄ± hedefler. Temel makine Ã¶ÄŸrenmesi algoritmasÄ± olarak **K-En YakÄ±n KomÅŸu (KNN)** kullanÄ±lmÄ±ÅŸtÄ±r.

Projenin asÄ±l amacÄ± sadece sÄ±nÄ±flandÄ±rma yapmak deÄŸil, **Boyut Ä°ndirgeme (Dimensionality Reduction)** tekniklerinin model performansÄ± ve karar sÄ±nÄ±rlarÄ± Ã¼zerindeki etkisini karÅŸÄ±laÅŸtÄ±rmalÄ± olarak analiz etmektir.

### ğŸ” KullanÄ±lan Teknikler ve Algoritmalar
1.  **K-En YakÄ±n KomÅŸu (KNN):** `GridSearchCV` kullanÄ±larak en iyi komÅŸu sayÄ±sÄ± ($k$) optimize edilmiÅŸ ve sÄ±nÄ±flandÄ±rma yapÄ±lmÄ±ÅŸtÄ±r.
2.  **Local Outlier Factor (LOF):** Veri setindeki yoÄŸunluk tabanlÄ± aykÄ±rÄ± deÄŸerleri (outliers) tespit etmek ve temizlemek iÃ§in kullanÄ±lan denetimsiz bir yÃ¶ntemdir.
3.  **PCA (Temel BileÅŸen Analizi):** Veriyi varyansÄ±n en yÃ¼ksek olduÄŸu yÃ¶ne iz dÃ¼ÅŸÃ¼ren, *denetimsiz* (unsupervised) bir boyut indirgeme yÃ¶ntemidir.
4.  **NCA (KomÅŸuluk BileÅŸenleri Analizi):** SÄ±nÄ±flandÄ±rma baÅŸarÄ±mÄ±nÄ± maksimize edecek doÄŸrusal dÃ¶nÃ¼ÅŸÃ¼mÃ¼ Ã¶ÄŸrenen, *denetimli* (supervised) bir yÃ¶ntemdir.

---

### âš™ï¸ Ä°ÅŸ AkÄ±ÅŸÄ± (Workflow)

1.  **KeÅŸifÃ§i Veri Analizi (EDA):** Veri yapÄ±sÄ±nÄ± anlamak iÃ§in daÄŸÄ±lÄ±mlar ve korelasyonlar incelendi.
2.  **Veri Temizleme:** **LOF** algoritmasÄ± ile aykÄ±rÄ± deÄŸerler tespit edildi ve veri setinden Ã§Ä±karÄ±ldÄ±.
3.  **Ã–n Ä°ÅŸleme:**
    * Hedef deÄŸiÅŸkenler kodlandÄ± (M=1, B=0).
    * **StandardScaler** uygulandÄ± (KNN mesafe tabanlÄ± bir algoritma olduÄŸu iÃ§in Ã¶lÃ§eklendirme kritik Ã¶nem taÅŸÄ±r).
4.  **Hiperparametre AyarÄ±:** En uygun $k$ deÄŸerini bulmak iÃ§in 10-katlÄ± Ã§apraz doÄŸrulama (CV) ile `GridSearchCV` kullanÄ±ldÄ±.
5.  **Boyut Ä°ndirgeme ve GÃ¶rselleÅŸtirme:**
    * 30 Ã¶zellikli veri seti **PCA** ve **NCA** ile 2 boyuta indirgendi.
    * Karar sÄ±nÄ±rlarÄ± (decision boundaries) gÃ¶rselleÅŸtirilerek karÅŸÄ±laÅŸtÄ±rÄ±ldÄ±.

---

### ğŸ“Š GÃ¶rseller ve SonuÃ§lar

#### 1. Korelasyon Analizi
Ã–zelliklerin birbirleriyle ve teÅŸhis (target) ile olan iliÅŸkisini gÃ¶steren Ä±sÄ± haritasÄ±.
![Correlation Heatmap](images/correlation_heatmap.png)

#### 2. AykÄ±rÄ± DeÄŸer Tespiti (LOF)
Veri setinin genel yoÄŸunluÄŸundan sapan noktalar tespit edilerek temizlendi.
![Outlier Detection](images/outlier_detection.png)

#### 3. KarÅŸÄ±laÅŸtÄ±rma: PCA ve NCA
Bu bÃ¶lÃ¼m projenin en Ã¶nemli Ã§Ä±ktÄ±sÄ±dÄ±r.

* **PCA Sonucu:** PCA varyansa odaklandÄ±ÄŸÄ± iÃ§in sÄ±nÄ±flarÄ± ayÄ±rmada fena deÄŸildir ancak karar sÄ±nÄ±rlarÄ± karmaÅŸÄ±ktÄ±r.
    ![PCA Boundary](images/pca_boundary.png)

* **NCA Sonucu (Kazanan):** NCA, eÄŸitim sÄ±rasÄ±nda etiketleri (labels) kullandÄ±ÄŸÄ± iÃ§in sÄ±nÄ±flarÄ± birbirinden uzaklaÅŸtÄ±rmayÄ± Ã¶ÄŸrenir. AÅŸaÄŸÄ±da gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ Ã¼zere, **Mavi ve Turuncu alanlar Ã§ok daha net ayrÄ±lmÄ±ÅŸtÄ±r.**
    ![NCA Boundary](images/nca_boundary.png)

#### 4. Hata Analizi
NCA destekli KNN modelimiz test setinde **%99 baÅŸarÄ±** gÃ¶stermiÅŸtir. AÅŸaÄŸÄ±daki grafikte modelin yanlÄ±ÅŸ tahmin ettiÄŸi **tek bir nokta** kÄ±rmÄ±zÄ± ile iÅŸaretlenmiÅŸtir.
![Wrong Classified](images/wrong_classified.png)

---

## ğŸ“‚ Folder Structure / Dosya YapÄ±sÄ±

```text
Breast-Cancer-KNN-Analysis/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data.csv          # Dataset
â”‚
â”œâ”€â”€ images/               # Generated Plots / OluÅŸturulan Grafikler
â”‚   â”œâ”€â”€ correlation_heatmap.png
â”‚   â”œâ”€â”€ outlier_detection.png
â”‚   â”œâ”€â”€ pca_boundary.png
â”‚   â”œâ”€â”€ nca_boundary.png
â”‚   â””â”€â”€ wrong_classified.png
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ proje1.py         # Main Source Code / Ana Kaynak Kod
â”‚
â”œâ”€â”€ models/               # Saved Models / Kaydedilen Modeller
â”œâ”€â”€ results/              # Analysis Results / Analiz SonuÃ§larÄ±
â”œâ”€â”€ requirements.txt      # Dependencies / Gerekli KÃ¼tÃ¼phaneler
â””â”€â”€ README.md             # Project Documentation
ğŸš€ How to Run / NasÄ±l Ã‡alÄ±ÅŸtÄ±rÄ±lÄ±r?
Clone the repository / Repoyu klonlayÄ±n:

Bash

git clone [https://github.com/busrademirrr/Breast-Cancer-KNN-Analysis.git](https://github.com/busrademirrr/Breast-Cancer-KNN-Analysis.git)
Install dependencies / Gerekli kÃ¼tÃ¼phaneleri yÃ¼kleyin:

Bash

pip install -r requirements.txt
Run the script / Kodu Ã§alÄ±ÅŸtÄ±rÄ±n:

Bash

cd src
python proje1.py
ğŸ”— Author / Yazar
BÃ¼ÅŸra Demir GitHub Profile
